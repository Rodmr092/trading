{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#RASPADO DE COMPONENTES HISTÓRICOS S&P 500"
      ],
      "metadata": {
        "id": "ouSraQ2-aMUK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGOSj7-qZROJ",
        "outputId": "699f27ee-bcbf-4855-ec31-6cf88ddbe7cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The HTML content has been successfully extracted and parsed.\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the URL of the Wikipedia page for scraping\n",
        "URL = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "\n",
        "# Function to make the HTTP request and obtain the content\n",
        "def get_html_content(url):\n",
        "    response = requests.get(url)\n",
        "    # Confirm that the request was successful (HTTP status code 200)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        raise Exception(f\"Error in obtaining page content, status code: {response.status_code}\")\n",
        "\n",
        "# Function to parse HTML content with BeautifulSoup\n",
        "def parse_html_to_soup(html_content):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    # Confirm that the BeautifulSoup object was created\n",
        "    return soup\n",
        "\n",
        "# Get the HTML content of the Wikipedia page\n",
        "html_content = get_html_content(URL)\n",
        "\n",
        "# Parse the HTML content to get the BeautifulSoup object\n",
        "soup = parse_html_to_soup(html_content)\n",
        "\n",
        "# Verify that significant content was extracted\n",
        "# To do this, look for a distinctive element of the page that we know should be present\n",
        "test_element = soup.find('h1', id=\"firstHeading\")\n",
        "assert test_element is not None, \"The HTML content does not contain the expected element.\"\n",
        "\n",
        "print(\"The HTML content has been successfully extracted and parsed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract the data from the current S&P 500 constituents table\n",
        "def extract_current_snp_data(soup):\n",
        "    table = soup.find('table', {'id': 'constituents'})\n",
        "    rows = table.find_all('tr')[1:]  # Exclude the table header\n",
        "\n",
        "    current_data = []\n",
        "    for row in rows:\n",
        "        cols = row.find_all('td')\n",
        "        security = cols[1].text.strip()\n",
        "        symbol = cols[0].text.strip()\n",
        "        current_data.append({\n",
        "            'Security': security,\n",
        "            'Symbol': symbol,\n",
        "            'Date': '1900-01-01'  # Fixed date for original members\n",
        "        })\n",
        "\n",
        "    return current_data\n",
        "\n",
        "# Function to extract historical changes data\n",
        "def extract_historical_changes_data(soup):\n",
        "    table = soup.find('table', {'id': 'changes'})\n",
        "    rows = table.find_all('tr')[1:]  # Exclude the table header\n",
        "\n",
        "    historical_data = []\n",
        "    for i, row in enumerate(rows):\n",
        "        cols = row.find_all('td')\n",
        "        if len(cols) < 6:  # Ensure there are enough columns\n",
        "            print(f\"Row {i+1} skipped: does not contain enough columns.\")\n",
        "            continue\n",
        "\n",
        "        # Parse the date and ensure it's in the correct format\n",
        "        date_text = cols[0].text.strip()\n",
        "        try:\n",
        "            date = datetime.strptime(date_text, '%B %d, %Y').strftime('%Y-%m-%d')\n",
        "        except ValueError:\n",
        "            print(f\"Error parsing the date in row {i+1}: {date_text}\")\n",
        "            continue\n",
        "\n",
        "        # Extract symbols and securities for added and removed entries\n",
        "        added_symbol = cols[1].text.strip()\n",
        "        added_security = cols[2].text.strip()\n",
        "        removed_symbol = cols[3].text.strip()\n",
        "        removed_security = cols[4].text.strip()\n",
        "\n",
        "        # Add to the DataFrame the added and removed values as separate entries\n",
        "        historical_data.append({'Security': added_security, 'Symbol': added_symbol, 'Date': date, 'Change': 'Added'})\n",
        "        historical_data.append({'Security': removed_security, 'Symbol': removed_symbol, 'Date': date, 'Change': 'Removed'})\n",
        "\n",
        "    return historical_data\n",
        "\n",
        "# Extract data and create DataFrames\n",
        "current_data = extract_current_snp_data(soup)\n",
        "historical_data = extract_historical_changes_data(soup)\n",
        "\n",
        "dataframe_current = pd.DataFrame(current_data)\n",
        "dataframe_historical = pd.DataFrame(historical_data)\n",
        "\n",
        "# Display the first records to confirm\n",
        "print(dataframe_current.head())\n",
        "print(dataframe_historical.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ltMRmTvee-A",
        "outputId": "d4733160-9c5d-4ffe-9e70-bc68d9c51a3e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 1 skipped: does not contain enough columns.\n",
            "      Security Symbol        Date\n",
            "0           3M    MMM  1900-01-01\n",
            "1  A. O. Smith    AOS  1900-01-01\n",
            "2       Abbott    ABT  1900-01-01\n",
            "3       AbbVie   ABBV  1900-01-01\n",
            "4    Accenture    ACN  1900-01-01\n",
            "              Security Symbol        Date   Change\n",
            "0              Hubbell   HUBB  2023-10-18    Added\n",
            "1        Organon & Co.    OGN  2023-10-18  Removed\n",
            "2  Lululemon Athletica   LULU  2023-10-18    Added\n",
            "3  Activision Blizzard   ATVI  2023-10-18  Removed\n",
            "4                              2023-10-03    Added\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datos faltantes"
      ],
      "metadata": {
        "id": "Tvk9YxKLaLmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Revisar datos faltantes en la columna 'Symbol' para el DataFrame de componentes actuales\n",
        "missing_symbols_current = dataframe_current['Symbol'].isnull().sum()\n",
        "print(\"Datos faltantes en la columna 'Symbol' para los componentes actuales del S&P 500:\")\n",
        "print(missing_symbols_current)\n",
        "print(\"\\nFilas con datos faltantes en la columna 'Symbol' para los componentes actuales del S&P 500:\")\n",
        "print(dataframe_current[dataframe_current['Symbol'].isnull()])\n",
        "\n",
        "# Revisar datos faltantes en la columna 'Symbol' para el DataFrame de cambios históricos\n",
        "missing_symbols_historical = dataframe_historical['Symbol'].isnull().sum()\n",
        "print(\"\\nDatos faltantes en la columna 'Symbol' para los cambios históricos del S&P 500:\")\n",
        "print(missing_symbols_historical)\n",
        "print(\"\\nFilas con datos faltantes en la columna 'Symbol' para los cambios históricos del S&P 500:\")\n",
        "print(dataframe_historical[dataframe_historical['Symbol'].isnull()])\n",
        "\n",
        "# Identificar símbolos que son cadenas vacías o solo espacios en el DataFrame de componentes actuales\n",
        "empty_symbols_current = dataframe_current[dataframe_current['Symbol'].str.strip() == '']\n",
        "print(\"Símbolos vacíos en los componentes actuales del S&P 500:\")\n",
        "print(empty_symbols_current)\n",
        "\n",
        "# Identificar símbolos que son cadenas vacías o solo espacios en el DataFrame de cambios históricos\n",
        "empty_symbols_historical = dataframe_historical[dataframe_historical['Symbol'].str.strip() == '']\n",
        "print(\"\\nSímbolos vacíos en los cambios históricos del S&P 500:\")\n",
        "print(empty_symbols_historical)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9A8cw4Ig2hY",
        "outputId": "08502c3b-b099-4799-a6ba-721a61c731d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos faltantes en la columna 'Symbol' para los componentes actuales del S&P 500:\n",
            "0\n",
            "\n",
            "Filas con datos faltantes en la columna 'Symbol' para los componentes actuales del S&P 500:\n",
            "Empty DataFrame\n",
            "Columns: [Security, Symbol, Date]\n",
            "Index: []\n",
            "\n",
            "Datos faltantes en la columna 'Symbol' para los cambios históricos del S&P 500:\n",
            "0\n",
            "\n",
            "Filas con datos faltantes en la columna 'Symbol' para los cambios históricos del S&P 500:\n",
            "Empty DataFrame\n",
            "Columns: [Security, Symbol, Date, Change]\n",
            "Index: []\n",
            "Símbolos vacíos en los componentes actuales del S&P 500:\n",
            "Empty DataFrame\n",
            "Columns: [Security, Symbol, Date]\n",
            "Index: []\n",
            "\n",
            "Símbolos vacíos en los cambios históricos del S&P 500:\n",
            "    Security Symbol        Date   Change\n",
            "4                    2023-10-03    Added\n",
            "7                    2023-10-02  Removed\n",
            "24                   2023-01-05    Added\n",
            "27                   2023-01-04  Removed\n",
            "32                   2022-12-19    Added\n",
            "35                   2022-12-15  Removed\n",
            "48                   2022-06-21    Added\n",
            "62                   2022-02-03    Added\n",
            "65                   2022-02-02  Removed\n",
            "84                   2021-06-04    Added\n",
            "87                   2021-06-03  Removed\n",
            "108                  2020-10-12    Added\n",
            "111                  2020-10-09  Removed\n",
            "132                  2020-04-06    Added\n",
            "134                  2020-04-06    Added\n",
            "137                  2020-04-03  Removed\n",
            "139                  2020-04-03  Removed\n",
            "329                  2016-04-08  Removed\n",
            "352                  2015-12-15    Added\n",
            "365                  2015-09-18  Removed\n",
            "367                  2015-09-18  Removed\n",
            "369                  2015-09-18  Removed\n",
            "419                  2014-08-06  Removed\n",
            "433                  2014-04-03  Removed\n",
            "587                  2009-06-29  Removed\n",
            "588                  2009-06-25    Added\n",
            "629                  2007-07-02  Removed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar filas donde la columna 'Symbol' contiene una cadena vacía o solo espacios en blanco\n",
        "dataframe_historical_cleaned = dataframe_historical[dataframe_historical['Symbol'].str.strip() != '']\n",
        "\n",
        "# Verificar que las filas han sido eliminadas\n",
        "print(dataframe_historical_cleaned)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lafuDy5h-wb",
        "outputId": "b747d6a8-b890-46bc-fd17-6fbe4387d763"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          Security Symbol        Date   Change\n",
            "0                          Hubbell   HUBB  2023-10-18    Added\n",
            "1                    Organon & Co.    OGN  2023-10-18  Removed\n",
            "2              Lululemon Athletica   LULU  2023-10-18    Added\n",
            "3              Activision Blizzard   ATVI  2023-10-18  Removed\n",
            "5                   DXC Technology    DXC  2023-10-03  Removed\n",
            "..                             ...    ...         ...      ...\n",
            "663                     General Re    GRN  1998-12-11  Removed\n",
            "664                      Compuware   CPWR  1998-12-11    Added\n",
            "665                     SunAmerica    SUN  1998-12-11  Removed\n",
            "666  Countrywide Credit Industries    CCI  1997-06-17    Added\n",
            "667                         USLife    USL  1997-06-17  Removed\n",
            "\n",
            "[641 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Identificar símbolos que son cadenas vacías o solo espacios en el DataFrame de cambios históricos\n",
        "empty_symbols_historical = dataframe_historical_cleaned[dataframe_historical_cleaned['Symbol'].str.strip() == '']\n",
        "print(\"\\nSímbolos vacíos en los cambios históricos del S&P 500:\")\n",
        "print(empty_symbols_historical)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmSrU7tgiGO8",
        "outputId": "65083de5-35c7-436d-9141-95a9b0143c27"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Símbolos vacíos en los cambios históricos del S&P 500:\n",
            "Empty DataFrame\n",
            "Columns: [Security, Symbol, Date, Change]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el DataFrame de componentes actuales del S&P 500 en un archivo CSV\n",
        "dataframe_current.to_csv('current_snp500.csv', index=False)\n",
        "\n",
        "# Guardar el DataFrame de cambios históricos del S&P 500 limpio en un archivo CSV\n",
        "dataframe_historical_cleaned.to_csv('historical_changes_snp500.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZhqtEYa5iz5G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear base de consulta (Si el stock pertenecía o no al S&P)"
      ],
      "metadata": {
        "id": "WJeo7CBKmdOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Combine and Prepare DataFrames\n",
        "def preparar_dataframes(dataframe_current, dataframe_historical):\n",
        "    start_date = pd.to_datetime('1900-01-01')\n",
        "    dataframe_current['Date'] = start_date\n",
        "    dataframe_current['Change'] = 'Added'\n",
        "\n",
        "    # Create a copy of the added data from the historical dataframe\n",
        "    added_historical = dataframe_historical[dataframe_historical['Change'] == 'Added'].drop_duplicates(subset='Symbol', keep='first')\n",
        "\n",
        "    # Update the current dataframe with the addition data from historical\n",
        "    for index, row in added_historical.iterrows():\n",
        "        current_index = dataframe_current[dataframe_current['Symbol'] == row['Symbol']].index\n",
        "        if not current_index.empty:\n",
        "            dataframe_current.loc[current_index, 'Date'] = row['Date']\n",
        "\n",
        "    combined_dataframe = pd.concat([dataframe_current, dataframe_historical]).drop_duplicates(subset=['Symbol', 'Date', 'Change'], keep='last')\n",
        "    combined_dataframe.sort_values(by=['Symbol', 'Date'], inplace=True)\n",
        "\n",
        "    return combined_dataframe, added_historical\n",
        "\n",
        "# Step 2: Create Stock Status Dictionary\n",
        "def crear_diccionario_estados(combined_dataframe, added_historical):\n",
        "    statuses = {}\n",
        "    start_date = pd.to_datetime('1900-01-01')\n",
        "    for _, row in combined_dataframe.iterrows():\n",
        "        if row['Symbol'] not in statuses:\n",
        "            statuses[row['Symbol']] = []\n",
        "            # If the stock was removed but has no addition date, assign the start date\n",
        "            if row['Change'] == 'Removed' and row['Symbol'] not in added_historical['Symbol'].values:\n",
        "                statuses[row['Symbol']].append((start_date, 'Added'))\n",
        "        statuses[row['Symbol']].append((row['Date'], row['Change']))\n",
        "    return statuses\n",
        "\n",
        "# Step 3: Function to Check Membership\n",
        "def verificar_pertenencia(symbol, date, statuses):\n",
        "    date = pd.to_datetime(date)  # Ensure 'date' is a Timestamp\n",
        "    changes = statuses.get(symbol, [])\n",
        "\n",
        "    was_member = False\n",
        "    for change_date, change_status in sorted(changes, key=lambda x: pd.to_datetime(x[0])):\n",
        "        if pd.to_datetime(change_date) > date:\n",
        "            break\n",
        "        was_member = change_status == 'Added'\n",
        "    return was_member\n",
        "\n",
        "# Step 4: Function to Process Multiple Queries\n",
        "def procesar_consultas(queries, statuses):\n",
        "    results = []\n",
        "    for symbol, date in queries:\n",
        "        belongs = verificar_pertenencia(symbol, date, statuses)\n",
        "        results.append((symbol, date, belongs))\n",
        "    return results\n",
        "\n",
        "# Prepare DataFrames and create the status dictionary\n",
        "combined_dataframe, added_historical = preparar_dataframes(dataframe_current, dataframe_historical)\n",
        "statuses = crear_diccionario_estados(combined_dataframe, added_historical)\n",
        "\n",
        "# Example usage\n",
        "queries = [(\"HPH\", \"1999-01-01\"), (\"HPH\", \"2000-01-01\")]\n",
        "results = procesar_consultas(queries, statuses)\n",
        "for symbol, date, belongs in results:\n",
        "    print(f\"The symbol {symbol} {'was' if belongs else 'was not'} a member of the S&P 500 on {date}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtYnvQ0zYkBF",
        "outputId": "29b60d0d-ccf4-47d3-c11c-665e1c00eefc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The symbol HPH was a member of the S&P 500 on 1999-01-01.\n",
            "The symbol HPH was not a member of the S&P 500 on 2000-01-01.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-a989689e4e6c>:17: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
            "  combined_dataframe.sort_values(by=['Symbol', 'Date'], inplace=True)\n"
          ]
        }
      ]
    }
  ]
}